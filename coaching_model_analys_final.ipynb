{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf47b46-60da-4622-a535-0f71b53091fd",
   "metadata": {},
   "source": [
    "Load and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66afd8a-cda6-4dde-8977-5e3a156329b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Week Employee_ID    AHT  Schedule_Adherence    ACW  RONA  \\\n",
      "0   1/1/2024      EMP001  16.26               93.08  0.140     2   \n",
      "1   1/8/2024      EMP001  18.01               96.17  1.272     0   \n",
      "2  1/15/2024      EMP001  17.78               86.93  1.476     0   \n",
      "3  1/22/2024      EMP001  13.32               98.28  1.497     2   \n",
      "4  1/29/2024      EMP001   7.93               85.78  1.311     0   \n",
      "\n",
      "   Evaluation_Completed  Efficiency  Compliance  Logging  Professionalism  \\\n",
      "0                  True        85.0        95.0     95.0             95.0   \n",
      "1                  True        95.0        95.0     90.0            100.0   \n",
      "2                 False         NaN         NaN      NaN              NaN   \n",
      "3                 False         NaN         NaN      NaN              NaN   \n",
      "4                 False         NaN         NaN      NaN              NaN   \n",
      "\n",
      "   Exceptions  Knowledge  Guidance  QS_Adoption_Score Performance_Level  \\\n",
      "0       100.0       95.0     100.0               95.0           Exceeds   \n",
      "1        90.0      100.0      95.0               95.0           Exceeds   \n",
      "2         NaN        NaN       NaN                NaN     Not Evaluated   \n",
      "3         NaN        NaN       NaN                NaN     Not Evaluated   \n",
      "4         NaN        NaN       NaN                NaN     Not Evaluated   \n",
      "\n",
      "  Needs_Coaching  \n",
      "0             No  \n",
      "1             No  \n",
      "2  Not Evaluated  \n",
      "3  Not Evaluated  \n",
      "4  Not Evaluated  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "advisorskpi=pd.read_csv(\"multi_employee_dataset.csv\")\n",
    "\n",
    "#Display the first few rows\n",
    "\n",
    "print(advisorskpi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0494b-11c6-40fa-81fe-d0c14eae6fa9",
   "metadata": {},
   "source": [
    "Clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b90bea-fd81-4a28-b877-37c2096e2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['Week', 'Employee_ID', 'Performance_Level', 'Needs_Coaching'], dtype='object')\n",
      "Week                     object\n",
      "Employee_ID              object\n",
      "AHT                     float64\n",
      "Schedule_Adherence      float64\n",
      "ACW                     float64\n",
      "RONA                      int64\n",
      "Evaluation_Completed       bool\n",
      "Efficiency              float64\n",
      "Compliance              float64\n",
      "Logging                 float64\n",
      "Professionalism         float64\n",
      "Exceptions              float64\n",
      "Knowledge               float64\n",
      "Guidance                float64\n",
      "QS_Adoption_Score       float64\n",
      "Performance_Level        object\n",
      "Needs_Coaching           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Handle Missing Evaluation Scores for days with no evaluations\n",
    "\n",
    "#Define the evaluation related colums\n",
    "eval_cols=[\"QS_Adoption_Score\", \"Professionalism\", \"Logging\", \"Compliance\", \"Knowledge\", \"Efficiency\", \"Exceptions\", \"Guidance\"]\n",
    "\n",
    "#Replace NaN with \"No Evaluation\"\n",
    "advisorskpi[eval_cols]=advisorskpi[eval_cols].fillna(\"No Evaluation\")\n",
    "\n",
    "#Remove the duplicate \n",
    "advisorskpi_no_duplicates=advisorskpi.drop_duplicates()\n",
    "\n",
    "#convert numeric columns to proper data \n",
    "numeric_cols=[ \"AHT\", \"Schedule_Adherence\", \"ACW\",\"RONA\",\"Efficiency\", \"Compliance\", \"Logging\", \"Professionalism\", \"Exceptions\", \"Knowledge\", \"Guidance\",\"QS_Adoption_Score\"]\n",
    "\n",
    "# Convert numeric columns to numeric type\n",
    "advisorskpi[numeric_cols]=advisorskpi[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "#identify categorial columns \n",
    "categorical_cols = advisorskpi.select_dtypes(include='object').columns\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "#print Data types \n",
    "print(advisorskpi.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712570e1-1d22-4390-a384-80c4e7153a15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d23707-62fe-45c2-ae0b-1ed3d5145fa9",
   "metadata": {},
   "source": [
    "Train a regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2843ccc-54b6-4aa3-bd92-56515a9bdb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Save cleaned dataset to a CSV file \n",
    "advisorskpi.to_csv(\"cleaned_advisorskpi.csv\", index=False)\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "cleaned_advisorskpi = pd.read_csv(\"cleaned_advisorskpi.csv\")\n",
    "\n",
    "# Create the next QS score column\n",
    "cleaned_advisorskpi[\"Next_QS_Score\"] = cleaned_advisorskpi[\"QS_Adoption_Score\"].shift(-1)\n",
    "\n",
    "# Drop the last row (it has no next QS score)\n",
    "cleaned_advisorskpi = cleaned_advisorskpi.dropna(subset=[\"Next_QS_Score\"])\n",
    "\n",
    "# Optional: reset index\n",
    "cleaned_advisorskpi = cleaned_advisorskpi.reset_index(drop=True)\n",
    "\n",
    "# Select input features and target variable\n",
    "features = [\"AHT\", \"ACW\", \"Schedule_Adherence\", \"RONA\"]\n",
    "X = cleaned_advisorskpi[features]\n",
    "y = cleaned_advisorskpi[\"Next_QS_Score\"]\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on full dataset\n",
    "cleaned_advisorskpi[\"Predicted_Next_QS\"] = model.predict(X_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69915068-0f80-42e1-b641-6e53ae6dd19d",
   "metadata": {},
   "source": [
    "Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab3c5a27-8b7c-47e8-af4a-7f4697bf063c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (4292645000.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"R² Score:\", r2_score(y_test, y_pred))\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ffae7-3d97-4e07-9222-56a14e35d581",
   "metadata": {},
   "source": [
    "Apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148cd6b-6180-404e-8450-308fe5b4c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_advisorskpi[\"Coaching_Reason\"] = cleaned_advisorskpi.apply(coaching_reason, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85524e-fcec-4253-9176-fa2bbe34a987",
   "metadata": {},
   "source": [
    "Turning the function into a readable coaching message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f1371-a69b-4cdf-8f93-ffe7c47b9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_advisorskpi[\"Coaching_Message\"] = cleaned_advisorskpi.apply(\n",
    "    lambda row: f\"Predicted QS: {row['Predicted_Next_QS']:.1f}. Coaching: {row['Coaching_Recommended']}. Reason: {row['Coaching_Reason']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07f1f5-9198-4135-aeeb-9f2f4b4bcaa3",
   "metadata": {},
   "source": [
    "Define threshold for low predicted score (assuming QS Adoptions core ranges from o to 100, we decide below 80 needs coaching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a73a6-7ec7-4e57-b676-d68c6b901ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 80.0\n",
    "\n",
    "#Mark Yes if predicted next QS is below thhreshold otherwise No \n",
    "cleaned_advisorskpi[\"Coaching_Recommended\"] = np.where(cleaned_advisorskpi[\"Predicted_Next_QS\"] < threshold, \"Yes\", \"No\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0614720-7e0f-4ea5-8d9e-52e0a80283ef",
   "metadata": {},
   "source": [
    "Explain why the coaching is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a9af3-ccc0-4b8d-b94c-d673daec455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain why coaching is recommended\n",
    "def coaching_reason(row):\n",
    "    if row[\"Predicted_Next_QS\"] < 80:\n",
    "        if row[\"RONA\"] > 1:\n",
    "            return \"RONA too high\"\n",
    "        elif row[\"AHT\"] > 2:\n",
    "            return \"AHT above threshold\"\n",
    "        else:\n",
    "            return \"Low predicted QS score\"\n",
    "    else:\n",
    "        return \"On Track\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f825a0f-6695-4aec-8760-19122e68a3ee",
   "metadata": {},
   "source": [
    "Filter the dataframe to show only the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798395d-6293-489c-92bd-4f6035a1627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_cleaned_advisorskpi = cleaned_advisorskpi[[\"Date\", \"AHT\", \"ACW\", \"RONA\", \"Schedule_Adherence\", \n",
    "                \"QS_Adoption_Score\", \"Predicted_Next_QS\", \n",
    "                \"Coaching_Recommended\", \"Coaching_Reason\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0754f9e-e82a-4d19-a94e-83b048fcd939",
   "metadata": {},
   "source": [
    "Display the coaching report in the streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca9901-a1f4-4081-b547-196bc5ada736",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_file is not None \n",
    "\n",
    "    st.header(\"Coaching Report\")\n",
    "    # Compute predictions and add report columns as shown above\n",
    "   cleaned_advisorskpi[\"Predicted_Next_QS\"] = model.predict(cleaned_advisorskpi[features])\n",
    "    cleaned_advisorskpi[\"Coaching_Recommended\"] = np.where(cleaned_advisorskpi[\"Predicted_Next_QS\"] < threshold, \"Yes\", \"No\")\n",
    "    cleaned_advisorskpi[\"Coaching_Reason\"] = np.where(cleaned_advisorskpi[\"Coaching_Recommended\"] == \"Yes\",\n",
    "                                     \"Predicted QS adoption score below acceptable level\", \"\")\n",
    "    report_cleaned_advisorskpi = cleaned_advisorskpi[[\"Date\", \"AHT\", \"ACW\", \"RONA\", \"Schedule_Adherence\", \n",
    "                    \"QS_Adoption_Score\", \"Predicted_Next_QS\", \n",
    "                    \"Coaching_Recommended\", \"Coaching_Reason\"]]\n",
    "\n",
    "    st.dataframe(report_cleaned_advisorskpi)  # display the report as an interactive table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499908b-040e-4259-8a89-4437c42aa312",
   "metadata": {},
   "source": [
    "Add a download coaching report button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac414cb5-1c03-4d20-ab80-1e20987db997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to csv\n",
    "csv_data = report_cleaned_advisorskpi.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "#Add the download button widget\n",
    "st.download_button(\n",
    "    label=\"Download Coaching Report\",\n",
    "    data=csv_data,\n",
    "    file_name=\"coaching_report.csv\",\n",
    "    mime=\"text/csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
